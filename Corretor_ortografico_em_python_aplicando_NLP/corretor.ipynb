{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar u\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/artigos.txt\") as file:\n",
    "    artigos = file.read()\n",
    "\n",
    "print(artigos[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "## 1. Correcting Missing Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "lista_normalizada = normalizacao(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavra_exemplo = \"lgica\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []    \n",
    "    letras = \"abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç\"    \n",
    "    \n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    \n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas.append(palavra) # We must add the own word, so that the corrector doesn't corrects right words\n",
    "\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç', 'lgica']\n"
     ]
    }
   ],
   "source": [
    "print(gerador_palavras(palavra_exemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "def probabilidade(palavra):\n",
    "    return frequencia[palavra]/total_palavras\n",
    "\n",
    "\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(\"lógica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    \n",
    "    with open(nome_arquivo, \"r\") as file:\n",
    "        for linha in file:\n",
    "            correta, errada = linha.split()\n",
    "            lista_palavras_teste.append((correta, errada))\n",
    "    \n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"data/palavras.txt\")\n",
    "# lista_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta: acertou += 1\n",
    "    \n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "\n",
    "    return taxa_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0752688172043012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliador(lista_teste)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing wrong characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracters(fatias):\n",
    "    novas_palavras = []   \n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    \n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas.append(palavra) # We must add the own word, so that the corrector doesn't corrects right words\n",
    "\n",
    "    palavras_geradas += deletando_caracters(fatias)\n",
    "\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.39784946236559"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliador(lista_teste)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mixing up Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def troca_letra(fatias):\n",
    "    novas_palavras = []    \n",
    "    letras = \"abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç\"    \n",
    "    \n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    \n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas.append(palavra) # We must add the own word, so that the corrector doesn't corrects right words\n",
    "\n",
    "    palavras_geradas += deletando_caracters(fatias)\n",
    "\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(\"lígica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Switching up Two Sequential Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []    \n",
    "    \n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    \n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas.append(palavra) # We must add the own word, so that the corrector doesn't corrects right words\n",
    "\n",
    "    palavras_geradas += deletando_caracters(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(\"lógiac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634408602150538"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring out the error from missing words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            if correta not in vocabulario:\n",
    "                desconhecida += 1\n",
    "    \n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "    taxa_desconhecida = desconhecida/numero_palavras\n",
    "\n",
    "    return np.array([taxa_acerto, taxa_desconhecida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76.34408602,  6.98924731])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting Words N-distant \n",
    "\n",
    "Up until now, the corrector can only correct words that have a single mistake, now we'll run the corrector multiple times so that it is able to correct words that are N mistakes away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_turbinado(palavras_geradas):\n",
    "    # for _ in range(n_runs):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_corretor(\"lóiigica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador_turbinado(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        if correta not in vocabulario:\n",
    "                desconhecida += 1\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "            \n",
    "    \n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "    taxa_desconhecida = desconhecida/numero_palavras\n",
    "\n",
    "    return np.array([taxa_acerto, taxa_desconhecida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([76.34408602,  6.98924731]), array([55.37634409,  6.98924731]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliador(lista_teste, vocabulario)*100, avaliador_turbinado(lista_teste, vocabulario)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
